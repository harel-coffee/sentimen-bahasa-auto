{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36e146a-fe81-4ced-983a-8d8580a999fa",
   "metadata": {},
   "source": [
    "## Prepare our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c401de2c-bbb0-4fcc-94fc-8b4d28893886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Be sure to change the path to absolute path of your directory if you re-run, or restart the kernel instead.\n",
    "os.chdir(\"dataset/txt\")\n",
    "base = \"prastyo-sentiment_posneg.txt\"\n",
    "\n",
    "# Open input file and read it line by line\n",
    "input_stream = open(base, \"r\", encoding=\"utf8\")\n",
    "input_stream_lines = input_stream.readlines()\n",
    "input_stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129796a9-e998-45b6-bdc8-497c4a33c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate text and label from the input\n",
    "text = []\n",
    "for line in input_stream_lines:\n",
    "    text.append(line.split(\"\\t\")[0])\n",
    "    \n",
    "label = []\n",
    "for line in input_stream_lines:\n",
    "    label.append(line.split(\"\\t\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc09dccb-b5a1-41a4-91a2-b5f9ff82c14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1918 1918\n",
      "\n",
      "input_stream_lines: \n",
      " ['Apapun agama dan kepercayaanmu, sblum tidur, yuk doakan mereka yg dalam prwatan COVID-19, nakes yg menangani, pemerintah dan warga Indonesia agar bersatu visi, bebas dari pandemi ini dalam waktu sesingkat-singkatnya.\\tpos\\n'] \n",
      "\n",
      "text: \n",
      " ['Apapun agama dan kepercayaanmu, sblum tidur, yuk doakan mereka yg dalam prwatan COVID-19, nakes yg menangani, pemerintah dan warga Indonesia agar bersatu visi, bebas dari pandemi ini dalam waktu sesingkat-singkatnya.'] \n",
      "\n",
      "label: \n",
      " ['pos\\n']\n"
     ]
    }
   ],
   "source": [
    "# Check the size of input\n",
    "print(len(input_stream_lines), len(text))\n",
    "\n",
    "# Print the last sample\n",
    "print(\"\\ninput_stream_lines: \\n\", input_stream_lines[-1:],\n",
    "      \"\\n\\ntext: \\n\", text[-1:],\n",
    "      \"\\n\\nlabel: \\n\", label[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33517a6b-1ae9-465a-83b2-60f89bb89dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating output file\n",
    "os.chdir(\"../../output\")\n",
    "output = os.path.splitext(base)[0]+'-clean.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0bee1a-aed8-4880-8227-99cc07604e78",
   "metadata": {},
   "source": [
    "## Cleaning text data with **RegEx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4dbfc71-ba76-44b6-b6b7-0e1695e6d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "count=0\n",
    "with open(output, 'w') as f:\n",
    "    for line in text:\n",
    "        # Step-1: Non-ascii\n",
    "        res = re.sub(r'[^\\x00-\\x7F]+',' ', line)\n",
    "        # Step-2: URLs\n",
    "        res = re.sub(r'http[s]?\\:\\/\\/.[a-zA-Z0-9\\.\\/\\_?=%&#\\-\\+!]+',' ', res)\n",
    "        res = re.sub(r'pic.twitter.com?.[a-zA-Z0-9\\.\\/\\_?=%&#\\-\\+!]+',' ', res)\n",
    "        # Step-3: mentions\n",
    "        res = re.sub(r'\\@([\\w]+)',' ', res)\n",
    "        \n",
    "        \n",
    "        # !!! Choose One !!!\n",
    "        # Step-4_alt-1: remove hashtags\n",
    "        # res = re.sub(r'\\#([\\w]+)',' ', res)\n",
    "        # Step-4_alt-2: retain hashtags (split string by capital letter)**\n",
    "        res = re.sub(r'((?<=[a-z])[A-Z]|[A-Z](?=[a-z]))', ' \\\\1', res)\n",
    "        #res = re.sub(r'([A-Z])(?<=[a-z]\\1|[A-Za-z]\\1(?=[a-z]))',' \\\\1', res)\n",
    "        \n",
    "        \n",
    "        # Step-5: symbols\n",
    "        res = re.sub(r'[!$%^&*@#()_+|~=`{}\\[\\]%\\-:\";\\'<>?,.\\/]', ' ', res)\n",
    "        # Step-6: numbers\n",
    "        res = re.sub(r'[0-9]+','', res)\n",
    "        # Step-7: duplicate three consecutive character correction (eg. yukkk)\n",
    "        res = re.sub(r'([a-zA-Z])\\1\\1','\\\\1', res)\n",
    "\n",
    "        # Step-8: double/multiple spaces to single space\n",
    "        res = re.sub(' +', ' ', res)\n",
    "        # Step-9: space at the beginning and the end of a sentence\n",
    "        res = re.sub(r'^[ ]|[ ]$','', res)\n",
    "        \n",
    "        # Step-10: lowercase\n",
    "        res = res.lower()\n",
    "        \n",
    "        # Writing each replaced line to output file\n",
    "        # and returning its label\n",
    "        f.write(str(res+\"\\t\"+label[count]))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8299d8-bc8b-4323-8d60-daf4e8fa2453",
   "metadata": {},
   "source": [
    "## Note:\n",
    "For Step-4, choose either removing or retaining hashtags\n",
    "<blockquote> **ref: <i>https://stackoverflow.com/questions/1097901/regular-expression-split-string-by-capital-letter-but-ignore-tla</i></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b29be-079b-4e8a-8e68-ec0a96a3466d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
