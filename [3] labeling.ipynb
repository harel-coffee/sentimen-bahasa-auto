{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a215f4a-968c-473d-9c26-e6047e996013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Membaca data yang sudah dibersihkan dari karakter yang tidak diperlukan serta dari daftar kata tak baku dan stop words\n",
    "# Pastikan untuk mengganti path dengan absolute path direktorimu jika baris berikut dijalankan ulang, atau restart kernel.\n",
    "os.chdir(\"output\")\n",
    "base = \"prastyo-sentiment_posneg-clean-slang-stop.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63756b22-0eba-4c39-814a-1c5c03536554",
   "metadata": {},
   "source": [
    "### We'll remove duplicate lines first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24619e8-e4bc-4ff0-908c-8ff5bc7d8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 1918\n",
      "after: 1660\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "input_stream = open(base, \"r\", encoding=\"utf8\")\n",
    "text = input_stream.readlines()\n",
    "input_stream.close()\n",
    "print(\"before:\", len(text))\n",
    "\n",
    "# menghapus duplikasi kalimat dengan mengonversinya ke 'ordered dictionary'\n",
    "newtext = list(OrderedDict.fromkeys(text))\n",
    "print(\"after:\", len(newtext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5937aa14-ae6b-4443-974d-79e994ed074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ya utang pemerintah utang bangsa indonesia hutang nya captain covid kalo orang terserah but ya apapun pemerintah bala tentara allah swt sahabat nya \\tneg\\n', 'yuk kawal kebijakan pemerintah disalah oknum bertanggung indonesia menang lawan covid \\tpos\\n']\n",
      "['ya utang pemerintah utang bangsa indonesia hutang nya captain covid kalo orang terserah but ya apapun pemerintah bala tentara allah swt sahabat nya \\tneg\\n', 'yuk kawal kebijakan pemerintah disalah oknum bertanggung indonesia menang lawan covid \\tpos\\n']\n"
     ]
    }
   ],
   "source": [
    "print(text[:2],)\n",
    "print(newtext[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4a7459-5f4d-4734-a712-f32ec125ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan teks yang sudah dibersihkan ke file\n",
    "output = os.path.splitext(base)[0]+'-dup.txt'\n",
    "with open(output, 'w') as f:\n",
    "    for line in newtext:\n",
    "        f.write(str(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a0f83e-c347-405e-8539-5d59efa7f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Kita akan menggunakan kolom teks saja di tahap ini, tanpa kolom label\n",
    "Corpus = pd.read_csv(output, encoding='latin-1', header=None, sep=\"\\t\", names=['text', 'label'], usecols=['text'], dtype=str)\n",
    "\n",
    "# # ALTERNATIF\n",
    "# # Memisahkan teks dan label dengan membuat DataFrame dari list 'ordered dict'\n",
    "# df = pd.DataFrame(newtext, columns=['text'])\n",
    "# df[['text','label']] = df['text'].str.split('\\t',expand=True)\n",
    "# df['label'] = df['label'].str.split('\\n',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215ba3f-2b77-495b-adcd-0235de678039",
   "metadata": {},
   "source": [
    "## Pelabelan dengan **InSet** dan **sentiwords_id** (dari sentistrength_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aab90e3-149d-4958-b9db-4e86878fd78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(barang) bekas': -4, '(olahraga) bokser': -5, '(tua) uzur': -3, 'Anda': -4, ...}\n",
      "{'(hujan) gerimis': 1, '(warna) dadu': 3, 'Ahad': 3, 'Sri paduka': 4, ...}\n",
      "{'abadi': 5, 'absen': -3, 'abu-abu': -1, 'acuh': 4, ...}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import json\n",
    "import reprlib\n",
    "\n",
    "# Memanfaatkan nltk VADER untuk menggunakan leksikon kustom\n",
    "sia1A, sia1B, sia2 = SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer()\n",
    "# membersihkan leksikon VADER default\n",
    "sia1A.lexicon.clear()\n",
    "sia1B.lexicon.clear()\n",
    "sia2.lexicon.clear()\n",
    "\n",
    "# Membaca leksikon InSet\n",
    "# Leksikon InSet lexicon dibagi menjadi dua, yakni polaritas negatif dan polaritas positif;\n",
    "# kita akan menggunakan nilai compound saja untuk memberi label pada suatu kalimat\n",
    "with open('../leksikon/inset/_json_inset-neg.txt') as f:\n",
    "    data1A = f.read()\n",
    "with open('../leksikon/inset/_json_inset-pos.txt') as f:\n",
    "    data1B = f.read()\n",
    "\n",
    "# Membaca leksikon sentiwords_id\n",
    "with open('../leksikon/sentistrength_id/_json_sentiwords_id.txt') as f:\n",
    "    data2 = f.read()\n",
    "\n",
    "# Mengubah leksikon sebagai dictionary\n",
    "insetNeg = json.loads(data1A)\n",
    "insetPos = json.loads(data1B)\n",
    "senti = json.loads(data2)\n",
    "\n",
    "# Update leksikon VADER yang sudah 'dimodifikasi'\n",
    "sia1A.lexicon.update(insetNeg)\n",
    "sia1B.lexicon.update(insetPos)\n",
    "sia2.lexicon.update(senti)\n",
    "\n",
    "print(reprlib.repr(sia1A.lexicon))\n",
    "print(reprlib.repr(sia1B.lexicon))\n",
    "print(reprlib.repr(sia2.lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d77a8-71ea-4b99-8ef2-a475f40941c7",
   "metadata": {},
   "source": [
    "### Contoh: menghitung skor polaritas dari suatu kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a732e3f-959e-495b-b4f7-8986507dee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insetNeg:  {'neg': 0.526, 'neu': 0.474, 'pos': 0.0, 'compound': -0.875}\n",
      "insetPos:  {'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'compound': 0.9517}\n",
      "insetCpdSum: 'compound': 0.07669999999999999\n",
      "senti\t:  {'neg': 0.0, 'neu': 0.733, 'pos': 0.267, 'compound': 0.6124}\n"
     ]
    }
   ],
   "source": [
    "sample = \"kalau kamu sudah sampai sini kamu hebat ayo terus kamu pasti bisa\"\n",
    "print(\"insetNeg: \", sia1A.polarity_scores(sample))\n",
    "print(\"insetPos: \", sia1B.polarity_scores(sample))\n",
    "print(\"insetCpdSum: 'compound':\", sia1A.polarity_scores(sample)[\"compound\"] + sia1B.polarity_scores(sample)[\"compound\"])\n",
    "\n",
    "print(\"senti\\t: \", sia2.polarity_scores(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec7bfa-0e23-4689-8113-7f0faf350669",
   "metadata": {},
   "source": [
    "### Fungsi untuk mengklasifikasikan kalimat sebagai negatif/positif berdasarkan nilai *compound*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee46ee3-bbb7-4dfd-9379-3efea8296fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive_inset(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia1A.polarity_scores(tweet)[\"compound\"] + sia1B.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "def is_positive_senti(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia2.polarity_scores(tweet)[\"compound\"] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67aa857d-5e00-4b37-9255-cb301c488fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = Corpus[\"text\"]\n",
    "\n",
    "# Menulis hasil klasifikasi label untuk setiap kalimat berdasarkan nilai compound dari insetNeg dan insetPos\n",
    "output = os.path.splitext(base)[0]+'-lb-inset.txt'\n",
    "with open(output, 'w') as f:\n",
    "    for tweet in tweets:\n",
    "        if is_positive_inset(tweet) == True:\n",
    "            label = \"pos\"\n",
    "        else:\n",
    "            label = \"neg\"\n",
    "        f.write(str(label+'\\n'))\n",
    "\n",
    "# Menulis hasil klasifikasi label untuk setiap kalimat berdasarkan nilai compound dari sentiwords_id\n",
    "output = os.path.splitext(base)[0]+'-lb-senti.txt'\n",
    "with open(output, 'w') as f:\n",
    "    for tweet in tweets:\n",
    "        if is_positive_senti(tweet) == True:\n",
    "            label = \"pos\"\n",
    "        else:\n",
    "            label = \"neg\"\n",
    "        f.write(str(label+'\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a5de6-4da4-4a32-8892-1ce7fe6feb52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
